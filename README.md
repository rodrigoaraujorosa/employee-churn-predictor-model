# Employee Churn Predictor Model ğŸ¤–

Projeto de Machine Learning para prever o abandono (churn) de colaboradores em uma empresa, utilizando a base de dados `HR_Abandono.csv`. O modelo final atingiu **96.50% de acurÃ¡cia** usando algoritmo **KNN (K=7)**, capaz de identificar colaboradores com risco de saÃ­da e apoiar o RH em aÃ§Ãµes preventivas de retenÃ§Ã£o.

## ğŸ“Š Sobre o Projeto

Este projeto faz parte do **Desafio Machine Learning AvanÃ§ado - FIAP AI para DEVs (Fase 1)** e implementa um pipeline completo de ciÃªncia de dados, desde a anÃ¡lise exploratÃ³ria atÃ© a validaÃ§Ã£o de modelos de classificaÃ§Ã£o.

### Objetivo
Construir um modelo preditivo capaz de identificar colaboradores com alta probabilidade de deixar a empresa, permitindo que o RH tome aÃ§Ãµes preventivas de retenÃ§Ã£o.

### Dataset
- **Arquivo**: `data/raw/HR_Abandono.csv` (separador: ponto-e-vÃ­rgula)
- **Registros**: ~15.000 colaboradores
- **VariÃ¡vel Target**: `left` (0 = permaneceu, 1 = saiu)
- **Principais Features**:
  - `satisfaction_level`: NÃ­vel de satisfaÃ§Ã£o (0 a 1)
  - `last_evaluation`: Ãšltima avaliaÃ§Ã£o de desempenho (0 a 1)
  - `average_montly_hours`: MÃ©dia de horas trabalhadas por mÃªs
  - `time_spend_company`: Tempo de empresa (anos)
  - `num_project`: NÃºmero de projetos
  - `Work_accident`: Acidente de trabalho (0/1)
  - `promotion_last_5years`: PromoÃ§Ã£o nos Ãºltimos 5 anos (0/1)
  - `salary`: NÃ­vel salarial (low, medium, high)
  - `depto`: Departamento do colaborador

## ğŸ—‚ï¸ Estrutura do Projeto

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados brutos
â”‚   â”‚   â””â”€â”€ HR_Abandono.csv
â”‚   â”œâ”€â”€ processed/              # Dados processados
â”‚   â”œâ”€â”€ interim/                # Dados intermediÃ¡rios
â”‚   â””â”€â”€ external/               # Dados externos
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ FIAP_AI_para_DEVs_Fase_1_Desafio_Machine_Learning_AvanÃ§ado.ipynb
â”œâ”€â”€ src/                        # CÃ³digo fonte
â”œâ”€â”€ models/                     # Modelos treinados
â”œâ”€â”€ reports/                    # RelatÃ³rios e visualizaÃ§Ãµes
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ tests/                      # Testes unitÃ¡rios
â”œâ”€â”€ requirements.txt            # DependÃªncias principais
â”œâ”€â”€ requirements-dev.txt        # DependÃªncias de desenvolvimento
â””â”€â”€ README.md
```

## ğŸš€ ComeÃ§ando

### PrÃ©-requisitos
- Python 3.10 ou superior
- pip (gerenciador de pacotes Python)
- Graphviz (para visualizaÃ§Ã£o de Ã¡rvores de decisÃ£o). Baixe e instale o Graphviz atravÃ©s do [site oficial](https://graphviz.org/download/).
- VS Code com extensÃ£o Jupyter (recomendado)

### InstalaÃ§Ã£o

1. **Clone ou copie o projeto**
```bash
cd employee-churn-predictor-model
```

2. **Crie e ative um ambiente virtual**
```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar no Windows
.venv\Scripts\activate

# Ativar no Linux/Mac
source .venv/bin/activate
```

3. **Instale as dependÃªncias**
```bash
# DependÃªncias principais
pip install -r requirements.txt

# Opcional: dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt
```

4. **Instale pacotes adicionais para visualizaÃ§Ãµes**
```bash
pip install dtreeviz yellowbrick
```

### Executando o Notebook

1. Abra o VS Code na pasta do projeto:
```bash
code .
```

2. Abra o notebook: `notebooks/FIAP_AI_para_DEVs_Fase_1_Desafio_Machine_Learning_AvanÃ§ado.ipynb`

3. Selecione o kernel Python do ambiente virtual (`.venv`)

4. Execute as cÃ©lulas sequencialmente

## ğŸ“ˆ Pipeline de Machine Learning

### 1. AnÃ¡lise ExploratÃ³ria de Dados (EDA)
- âœ… VerificaÃ§Ã£o de valores nulos e duplicados
- âœ… IdentificaÃ§Ã£o e tratamento de outliers (ex: registro com 810 horas/mÃªs removido)
- âœ… ConversÃ£o de tipos de dados (satisfaction_level e last_evaluation de string para float)
- âœ… EstatÃ­stica descritiva detalhada
- âœ… AnÃ¡lise de correlaÃ§Ãµes e distribuiÃ§Ãµes
- âœ… VisualizaÃ§Ãµes: boxplots, histogramas, pairplots, heatmaps, grÃ¡ficos de contagem

### 2. PrÃ©-processamento
- **Limpeza**: RemoÃ§Ã£o de outliers e tratamento de inconsistÃªncias
- **Encoding**: One-Hot Encoding para variÃ¡veis categÃ³ricas (`salary`, `depto`)
- **SeleÃ§Ã£o de Features**: 8 variÃ¡veis finais selecionadas com base em anÃ¡lise de correlaÃ§Ã£o
- **Escalonamento**: StandardScaler aplicado em modelos que requerem normalizaÃ§Ã£o
- **DivisÃ£o**: 80% treino / 20% teste com estratificaÃ§Ã£o pela variÃ¡vel target

### 3. Modelos Treinados e Comparados
| Modelo | AcurÃ¡cia | Precision (Sai) | Recall (Sai) | F1-Score | ROC-AUC |
|--------|----------|----------------|--------------|----------|---------|
| **KNN (K=7)** â­ | **96.50%** | **95%** | **91%** | **93%** | **98%** |
| KNN (K=6) | 96.93% | 96% | 93% | 94% | 98% |
| SVM | 96.33% | 95% | 90% | 92% | 97% |
| Floresta AleatÃ³ria | 90.80% | 91% | 68% | 78% | - |
| Ãrvore de DecisÃ£o | 82.13% | 100% | 25% | 40% | - |
| RegressÃ£o LogÃ­stica | ~75% | - | - | - | - |

**Modelo Selecionado**: KNN (K=7)
- Melhor equilÃ­brio entre precisÃ£o e recall
- Apenas 59 falsos negativos (colaboradores que saÃ­ram mas foram classificados como permanentes)
- Evita problema de empate do K par (K=6)

### 4. ValidaÃ§Ã£o e MÃ©tricas
- âœ… Matriz de ConfusÃ£o
- âœ… RelatÃ³rios de ClassificaÃ§Ã£o (Precision, Recall, F1-Score)
- âœ… Curvas ROC com AUC
- âœ… AnÃ¡lise de Coeficientes (RegressÃ£o LogÃ­stica)
- âœ… ImportÃ¢ncia de Features (Ãrvores)
- âœ… VisualizaÃ§Ã£o de Ãrvores de DecisÃ£o com dtreeviz

## ğŸ” Principais Descobertas

### Fatores que mais influenciam a evasÃ£o:
1. **NÃ­vel de SatisfaÃ§Ã£o** ğŸ“‰: Forte correlaÃ§Ã£o negativa (-0.39) - quanto menor a satisfaÃ§Ã£o, maior a chance de saÃ­da
2. **SalÃ¡rio Baixo** ğŸ’°: ~68% dos que saem tÃªm salÃ¡rio baixo ou mÃ©dio
3. **Tempo de Empresa** â±ï¸: CorrelaÃ§Ã£o positiva (0.22) - colaboradores podem sair apÃ³s cumprir determinado tempo
4. **Horas Trabalhadas** ğŸ•: MÃ©dia mais alta entre quem sai

### Grupos de risco identificados:
- **Grupo 1**: Alta performance + baixa satisfaÃ§Ã£o (burnout)
- **Grupo 2**: Baixa performance + satisfaÃ§Ã£o mÃ©dia (~0.4)
- **Grupo 3**: InsatisfaÃ§Ã£o extrema (nÃ­vel â‰¤ 0.11) - 100% de evasÃ£o

## ğŸ“Š SaÃ­das e VisualizaÃ§Ãµes

O notebook gera:
- ğŸ“ˆ Histogramas e boxplots de todas as variÃ¡veis numÃ©ricas
- ğŸ”¥ Heatmap de correlaÃ§Ã£o
- ğŸ“Š GrÃ¡ficos de contagem por salÃ¡rio e departamento
- ğŸ¯ Matrizes de confusÃ£o para todos os modelos
- ğŸ“‰ Curvas ROC comparativas
- ğŸŒ³ VisualizaÃ§Ãµes de Ã¡rvores de decisÃ£o
- ğŸ“‹ RelatÃ³rios de classificaÃ§Ã£o com mÃ©tricas detalhadas

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem**: Python 3.10+
- **AnÃ¡lise e ManipulaÃ§Ã£o**: pandas, numpy
- **VisualizaÃ§Ã£o**: matplotlib, seaborn, dtreeviz, yellowbrick
- **Machine Learning**: scikit-learn
- **Ambiente**: Jupyter Notebook / JupyterLab

## âš ï¸ Dicas e SoluÃ§Ã£o de Problemas

### Erro ao carregar o CSV
- Confirme que o arquivo estÃ¡ em `data/raw/HR_Abandono.csv`
- Verifique o separador (`;` no cÃ³digo)
- No notebook, o caminho relativo Ã© `HR_Abandono.csv` pois o notebook estÃ¡ em `notebooks/`

### Kernel errado
- Selecione o kernel Python do ambiente virtual `.venv` no canto superior direito do notebook

### Avisos (Warnings)
- O notebook jÃ¡ inclui `warnings.filterwarnings("ignore")` para silenciar avisos nÃ£o crÃ­ticos

### Performance lenta
- O treinamento de alguns modelos pode levar alguns minutos
- KNN com grandes datasets pode ser mais lento na prediÃ§Ã£o

## ğŸ”„ Reprodutibilidade

Todos os processos aleatÃ³rios usam `random_state=42` para garantir resultados reprodutÃ­veis:
- DivisÃ£o treino/teste
- InicializaÃ§Ã£o de modelos
- Seed do NumPy

## ğŸ“ PrÃ³ximos Passos

- [ ] Implementar Grid Search para otimizaÃ§Ã£o de hiperparÃ¢metros
- [ ] Testar algoritmos de ensemble avanÃ§ados (XGBoost, LightGBM)
- [ ] Criar pipeline automatizado de retreinamento
- [ ] Desenvolver API REST para prediÃ§Ãµes em produÃ§Ã£o
- [ ] Implementar monitoramento de drift de dados

## ğŸ“„ LicenÃ§a

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

Uso educacional. Ajuste conforme necessÃ¡rio para seu contexto.

---

**Desenvolvido como parte do Desafio FIAP - AI para DEVs (Fase 1)**

